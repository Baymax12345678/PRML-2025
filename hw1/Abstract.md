<center>
  <strong style="font-size: 30px;">PRML 第一次作业报告</strong>
</center>

<center>
  郭树立	22376128@buaa.edu.cn
</center>

### Abstract

---

​	本报告针对给定的二维数据集进行线性拟合实验，使用最小二乘法、梯度下降法（GD）和牛顿法分别对训练数据进行拟合，并对比分析训练误差与测试误差。通过对实验结果的观察，发现线性模型在某些情况下无法很好地拟合数据，特别是当数据本身呈现非线性趋势时。针对这一问题，报告进一步探索了更为适合的数据拟合模型，并结合实验结果给出了合理的分析与解释。

### Introduction

---

​	数据拟合是统计学和机器学习中的一个核心问题，广泛应用于各类预测模型、参数估计以及科学实验数据的分析等领域。线性拟合是最常见的拟合方法之一，它假设数据可以通过一个线性方程来近似描述。然而，在实际应用中，许多数据集并非严格遵循线性关系，因此仅仅依赖线性模型进行拟合可能无法得到理想的结果。

​	本报告旨在探讨在不同拟合方法下，如何对给定的二维数据集进行准确的拟合。具体来说，我们使用了三种常见的拟合方法：最小二乘法（Least Squares），梯度下降法（Gradient Descent, GD）和牛顿法（Newton’s Method）。我们将通过实验分析这些方法在训练数据和测试数据上的表现，比较它们在不同情况中的拟合效果。

​	在初步的线性拟合实验后，报告将进一步探讨当线性模型无法很好拟合数据时，是否可以通过更为复杂的模型来改善拟合效果。我们将在非线性数据的背景下，分析并提出更合适的模型，并结合实验结果给出选择该模型的原因和分析。

​	通过本报告的实验与分析，期望能为实际数据拟合问题提供有益的见解，帮助选择最合适的拟合方法。

### **Methodology**

---

​	在本部分中，我们将详细描述所使用的数据拟合方法，以及每种方法的实现步骤和过程。

#### 1. 最小二乘法

最小二乘法是一种经典的线性回归方法，其目标是通过最小化训练数据中预测值与实际值之间的平方误差来找到最佳拟合直线。对于一个二维数据集，假设拟合模型为：
$$
y=\theta_0 + \theta_1x
$$
其中，$\theta_0$ 和 $\theta_1$ 是待优化的参数，最小二乘法通过求解以下的最小化问题来确定参数 $\theta$：
$$
J(\theta)=\sum_{i=1}^{n}(y_i-(\theta_0+\theta_1x_i))^2
$$
其中，$n$ 是训练数据的数量，$x_i$ 和 $y_i$ 分别是第 $ i$ 个数据点的输入和输出值。通过对 $J(\theta)$ 对 $ \theta_0$ 和 $\theta_1$ 进行偏导数计算，可以得到闭式解来直接计算最优参数。

#### 2. 梯度下降法

梯度下降法是一种迭代优化方法，通常用于解决无法通过解析解得到的最优化问题。在数据拟合中，梯度下降法通过不断调整参数 $\theta_0$ 和 $\theta_1$ 来减少损失函数的值，直到找到最优解。损失函数通常采用均方误差（MSE）形式：
$$
J(\theta) = \frac{1}{2n} \sum_{i=1}^{n} (y_i - (\theta_0 + \theta_1 x_i))^2
$$
梯度下降法通过以下更新规则迭代优化参数：
$$
\theta_j := \theta_j - \alpha \frac{\partial J(\theta)}{\partial \theta_j}
$$
其中，$\alpha$ 是学习率，$\frac{\partial J(\theta)}{\partial \theta_j}$ 是损失函数对 $\theta_j$ 的偏导数。梯度下降法需要选择合适的学习率，并在多个迭代中调整参数，直到损失函数收敛到最小值。

#### 3. 牛顿法

牛顿法是一种通过利用二阶导数信息来加速收敛的优化方法。它与梯度下降法类似，也通过迭代更新参数，但不同的是，牛顿法不仅依赖一阶导数（梯度），还依赖二阶导数（Hessian矩阵）来估计最优参数。更新规则为：
$$
\theta := \theta - H^{-1} \nabla J(\theta)
$$
其中，$\nabla J(\theta)$ 是梯度，$H$ 是损失函数的 Hessian 矩阵，表示损失函数关于 $\theta$ 的二阶导数。由于牛顿法考虑了二阶导数，通常可以比梯度下降法更快地收敛，尤其是在损失函数接近二次函数时。

#### 4. 多层感知机

多层感知器（MLP）是一种前馈神经网络，由多个层次的神经元组成。每个神经元接收前一层的输出并通过激活函数生成输出。MLP 常用于拟合复杂的非线性数据。在本实验中，我们使用 MLP 进行数据拟合。



### **Experimental Studies**

#### 线性拟合

根据三种不同的拟合方法，得到的拟合线性函数 $y=\theta_0+\theta_1x$ 的参数如下：

|            | 最小二乘法          | 梯度下降法          | 牛顿法               |
| ---------- | ------------------- | ------------------- | -------------------- |
| $\theta_0$ | -0.6487466967301856 | -0.6442592675352024 | -0.48497182098140834 |
| $\theta_1$ | 0.10894738685803713 | 0.10827265618339714 | 0.08065210903038995  |

三种线性拟合误差计算如下表：

|          | 最小二乘法         | 梯度下降法         | 牛顿法             |
| -------- | ------------------ | ------------------ | ------------------ |
| 训练误差 | 0.6134024281450051 | 0.6134075391306283 | 0.6207062918529508 |

三种线性拟合函数图像如下：

1. 最小二乘法

![image-20250318164003469](https://raw.githubusercontent.com/Baymax12345678/img_repo/master/img/image-20250318164003469.png)

2. 梯度下降法

![image-20250318164037051](https://raw.githubusercontent.com/Baymax12345678/img_repo/master/img/image-20250318164037051.png)

3. 牛顿迭代法

![image-20250318164057805](https://raw.githubusercontent.com/Baymax12345678/img_repo/master/img/image-20250318164057805.png)

#### 非线性拟合

我设计了如下网络结构：

```python
net = nn.Sequential(nn.Linear(1,256),nn.ReLU(),
                    nn.Linear(256,256),nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(256,256),nn.ReLU(),
                    nn.Dropout(0.3),
                    nn.Linear(256,256),nn.ReLU(),
                    nn.Dropout(0.4),
                    nn.Linear(256,256),nn.ReLU(),
                    nn.Dropout(0.5),
                    nn.Linear(256,128),nn.ReLU(),
                    nn.Dropout(0.6),
                    nn.Linear(128,32),nn.ReLU(),
                    nn.Linear(32,1))
```

通过 Xavier 初始化参数，利用 Adam 优化器进行训练，最终得到的拟合图像如下：

![image-20250318164655952](https://raw.githubusercontent.com/Baymax12345678/img_repo/master/img/image-20250318164655952.png)

训练误差为 0.16728125004629568。



### **Conclusions**

​	本报告通过对最小二乘法、梯度下降法、牛顿法和多层感知器（MLP）进行比较实验，发现对于简单线性数据，经典线性方法能够较好地拟合。然而，在数据呈现非线性趋势时，线性方法的拟合效果显著下降，MLP则表现出更好的拟合效果，尤其在处理复杂非线性数据时。牛顿法相较于其他线性方法收敛更快，效果更好，但计算复杂度较高。总体来说，对于具有非线性特征的数据，MLP作为一种灵活的非线性模型，能够提供更加精确的拟合结果，值得在实际应用中进一步探索。







